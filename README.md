# ğŸ¤– Avinashh Personal Assistant - RAG Chatbot

A modern, intelligent personal assistant powered by Retrieval-Augmented Generation (RAG) that answers questions about Lok Avinashh's professional background, skills, and experience. Built with Flask, React, and Groq AI.

## âœ¨ Features

- ğŸ’¬ **WhatsApp-Style Chat Interface** - Modern, responsive UI with real-time messaging
- ğŸ“„ **Resume PDF Preview** - Beautiful document card with one-click download
- ğŸ§  **Intelligent RAG System** - Retrieves relevant context from resume to answer questions
- âš¡ **Fast Responses** - Powered by Groq's lightning-fast LLM API
- ğŸ¯ **Smart Greeting Detection** - Proactively offers resume on greeting
- ğŸ” **Semantic Search** - Uses FAISS vector similarity search for accurate retrieval
- ğŸŒ **Production Ready** - Deployable to Render, Heroku, or any cloud platform

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React     â”‚â”€â”€â”€â”€â”€â–¶â”‚    Flask     â”‚â”€â”€â”€â”€â”€â–¶â”‚   Groq AI   â”‚
â”‚  Frontend   â”‚      â”‚   Backend    â”‚      â”‚     LLM     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚    FAISS     â”‚
                     â”‚ Vector Index â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
avinash-personal-assistant-rag/
â”œâ”€â”€ backend/                    # Flask backend
â”‚   â”œâ”€â”€ api.py                 # API endpoints & server
â”‚   â”œâ”€â”€ app.py                 # Application entry point
â”‚   â”œâ”€â”€ index_documents.py     # Document indexing script
â”‚   â”œâ”€â”€ rag_utils.py           # RAG retrieval logic
â”‚   â””â”€â”€ serve_models.py        # Groq LLM integration
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ react-app/             # React source code
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ App.jsx        # Main app component
â”‚   â”‚   â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”‚   â”‚   â””â”€â”€ App.css        # Styling
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ static/                # Built React app (production)
â”œâ”€â”€ data/                      # Source documents
â”‚   â””â”€â”€ resume.pdf
â”œâ”€â”€ embeddings/                # Generated vector index
â”‚   â”œâ”€â”€ resume.index           # FAISS index
â”‚   â””â”€â”€ resume_meta.json       # Chunk metadata
â”œâ”€â”€ resume/                    # Resume files for download
â”‚   â””â”€â”€ T_Lok_Avinashh Resume.pdf
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ runtime.txt                # Python version (for deployment)
â”œâ”€â”€ Procfile                   # Deployment config
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** 
- **Node.js 16+** (for frontend development)
- **Groq API Key** 

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd avinash-personal-assistant-rag
   ```

2. **Set up Python environment**
   ```bash
   python -m venv venv
   
   # Windows
   .\venv\Scripts\Activate.ps1
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure API Key**
   
   Create a `.env` file in the `backend/` directory:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   ```

5. **Index documents** (First time only)
   ```bash
   python backend/index_documents.py
   ```
   This creates the vector index from documents in `data/`

6. **Start the server**
   ```bash
   python backend/app.py
   ```
   
   Or use the convenience scripts:
   ```bash
   # Windows PowerShell
   .\start_server.ps1
   
   # Windows Command Prompt
   .\start_server.bat
   ```

7. **Open in browser**
   
   Navigate to: **http://localhost:7860**

## ï¿½ Development

### Frontend Development

The frontend is a React app built with Vite.

```bash
cd frontend/react-app

# Install dependencies
npm install

# Run development server
npm run dev

# Build for production
npm run build
```

The production build is automatically copied to `frontend/static/` for Flask to serve.

### Backend Development

The backend uses Flask with the following endpoints:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Serves React app |
| `/chat` | POST | Handles chat messages |
| `/health` | GET | Health check |
| `/resume/<filename>` | GET | Serves resume PDF |

### Adding New Documents

1. Place PDF, TXT, or MD files in `data/` folder
2. Re-run indexing:
   ```bash
   python backend/index_documents.py
   ```
3. Restart the server

## ğŸ¨ Features in Detail

### 1. Smart Greeting Detection
When users say "Hi", "Hello", etc., the assistant proactively asks if they want to see the resume.

### 2. Resume PDF Card
Instead of a plain link, the resume appears as a beautiful document card with:
- PDF icon and filename
- "Tap to download" description
- Prominent download button

### 3. Intelligent Question Answering
The RAG pipeline:
1. Embeds the user's question using Sentence Transformers
2. Retrieves top-3 most relevant chunks from FAISS index
3. Builds a context-aware prompt
4. Generates a natural answer using Groq's LLM

### 4. Response Cleaning
Removes verbose phrases like "Based on the context" and "According to the resume" for more natural, concise responses.

## ğŸ”§ Configuration

### Change LLM Model

Edit `backend/serve_models.py`:
```python
GROQ_MODEL = "llama-3.1-70b-versatile"  # or any Groq model
```

### Adjust Retrieval Settings

Edit `backend/rag_utils.py`:
```python
# Number of context chunks to retrieve
contexts = retrieve(question, top_k=3)

# Embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")
```

### Adjust Chunking

Edit `backend/index_documents.py`:
```python
chunk_size = 300  # Characters per chunk
overlap = 50      # Overlap between chunks
```

## ğŸŒ Deployment

### Deploy to Render

1. Push code to GitHub
2. Create new Web Service on [Render](https://render.com)
3. Connect your repository
4. Render will auto-detect `render.yaml` configuration
5. Add environment variable: `GROQ_API_KEY`
6. Deploy!

The app includes:
- `Procfile` - Gunicorn configuration
- `render.yaml` - Render deployment config
- `runtime.txt` - Python version specification

### Environment Variables

Set these in your deployment platform:
- `GROQ_API_KEY` - Your Groq API key
- `PORT` - Server port (auto-set by most platforms)
- `FLASK_ENV` - Set to `production` for production

## ğŸ“Š API Usage

### Chat Endpoint

**Request:**
```bash
curl -X POST http://localhost:7860/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What are Avinashh'\''s skills?"}'
```

**Response:**
```json
{
  "answer": "Avinashh has expertise in Python, Machine Learning, NLP..."
}
```

**Resume Request Response:**
```json
{
  "answer": "Sure! Here's Lok Avinashh's resume.",
  "document": {
    "url": "/resume/T_Lok_Avinashh%20Resume.pdf",
    "name": "T_Lok_Avinashh Resume.pdf",
    "type": "PDF"
  }
}
```

## ğŸ› Troubleshooting

### Server won't start
- âœ… Check if virtual environment is activated
- âœ… Install dependencies: `pip install -r requirements.txt`
- âœ… Verify `GROQ_API_KEY` is set
- âœ… Check if embeddings exist in `embeddings/` folder

### No answers generated
- âœ… Check `/health` endpoint for API status
- âœ… Verify Groq API key is valid
- âœ… Check server logs for errors
- âœ… Ensure documents are indexed

### Frontend not loading
- âœ… Check if React app is built: `npm run build` in `frontend/react-app`
- âœ… Verify `frontend/static/` contains built files
- âœ… Clear browser cache

### Import errors
- âœ… Activate virtual environment
- âœ… Reinstall dependencies: `pip install -r requirements.txt`

## ğŸ“¦ Dependencies

### Backend
- `flask` - Web framework
- `flask-cors` - CORS support
- `sentence-transformers` - Text embeddings
- `faiss-cpu` - Vector similarity search
- `pdfplumber` - PDF text extraction
- `requests` - HTTP client for Groq API
- `gunicorn` - Production WSGI server

### Frontend
- `react` - UI library
- `vite` - Build tool

## ğŸ¤ Contributing

This is a personal project, but suggestions and improvements are welcome!

## ğŸ“„ License

This project is for personal/educational use.

## ğŸ‘¨â€ğŸ’» Author

**Lok Avinashh**

For questions about this project, feel free to ask the chatbot itself! ğŸ˜„

---

Made with â¤ï¸ using Flask, React, and Groq AI
